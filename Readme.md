Perfecto üöÄ Te propongo una versi√≥n mejorada y m√°s ordenada del **README.md**, con un **Quick Start** al inicio (para que cualquiera pueda correr el proyecto r√°pido), una narrativa m√°s clara y un formato profesional.

---

````markdown
# Proyecto Final de NLP / Text Mining  
**Maestr√≠a en Data Mining ‚Äì UBA**

---

## Tema: LLM-based Feature Engineering

Este trabajo pr√°ctico final explora el uso de **Large Language Models (LLMs)** como herramienta para la generaci√≥n de *features* a partir de textos period√≠sticos. El objetivo es evaluar c√≥mo estas representaciones enriquecidas impactan en modelos predictivos tradicionales, con √©nfasis en el **forecasting de variables macroecon√≥micas** (ej. EMAE, inflaci√≥n).  

---

## üöÄ Quick Start

1. Clonar el repositorio:
   ```bash
   git clone <URL_DEL_REPO>
   cd <NOMBRE_DEL_REPO>
````

2. Crear entorno virtual en **Python 3.10**:

   ```bash
   python3.10 -m venv .venv
   source .venv/bin/activate   # Linux/Mac
   .venv\Scripts\activate      # Windows
   ```

3. Instalar dependencias:

   ```bash
   pip install -r requirements.txt
   ```
   
---

## üéØ Objetivos

* Dise√±ar un **pipeline completo** para la recolecci√≥n y preprocesamiento de noticias de medios digitales.
* **Periodo de an√°lisis:** 2025-01 a 2025-04.
* **Fuentes:** √Åmbito (Tom√°s), Clar√≠n (Ian), P√°gina/12 (Euge), Infobae (Leo), La Naci√≥n (Santi), Argentina.gob.
* **Campos a scrapear:** `{Fecha, T√≠tulo, Secci√≥n, Diario, Contenido}`.
* Aplicar LLMs para extraer *features* de alto nivel (**sentimiento, embeddings, clasificaciones contextuales**).
* Integrar dichas *features* en modelos de predicci√≥n y compararlas frente a un baseline sin LLMs.
* Evaluar **eficiencia y trade-offs** entre LLMs en la nube (GPT-4o mini / GPT-5 nano) y modelos locales (\~3B).
* Analizar **escalabilidad mediante procesamiento asincr√≥nico**.

---

## üõ†Ô∏è Metodolog√≠a

1. **Definici√≥n de la fuente de datos**

   * Selecci√≥n de diarios nacionales.
   * Determinaci√≥n de secciones relevantes (econom√≠a y pol√≠tica).
   * Delimitaci√≥n del per√≠odo temporal.

2. **Ingesta y construcci√≥n del dataset**

   * Scraping automatizado para obtener el *top-10* de noticias diarias por fuente.
   * Limpieza, normalizaci√≥n y almacenamiento en formato estructurado (Parquet).
   * Dataset base con variables `{fuente, secci√≥n, fecha, texto}`.

   Recursos:

   * [RSS La Naci√≥n](https://servicios.lanacion.com.ar/herramientas/rss/ayuda)
   * [Scraping ejemplos](https://hernanescu.github.io/2019/01/scraping-media/)

3. **LLM-based Feature Engineering**

   * **Prompt Engineering:** dise√±o de instrucciones para sentimiento y relevancia.
   * **Clasificaci√≥n:** outputs binarios y escalas (1 a 10).
   * **Embeddings contextuales:** representaciones vectoriales con LLMs.
   * **Procesamiento asincr√≥nico:** reducci√≥n de tiempo/costo con *requests* paralelos.

4. **Modelado predictivo**

   * Entrenamiento de modelos de forecasting econ√≥mico (Regresi√≥n, ARIMA, XGBoost).
   * Comparaci√≥n entre:

     * Baseline (sin features de LLMs)
     * Modelo + Features LLM
     * LLM predict directo
   * Evaluaci√≥n de impacto en m√©tricas predictivas.

---

## üìå Etapas de Desarrollo

* **A. Fuente de datos** ‚Üí definici√≥n de diarios, secciones y periodo.
* **B. Pipeline de ingesta** ‚Üí scraping, limpieza y dataset.
* **C. Feature Engineering con LLMs** ‚Üí prompts, embeddings, se√±ales sem√°nticas.
* **D. Procesamiento asincr√≥nico** ‚Üí requests paralelos a APIs/modelos locales.
* **E. Modelado** ‚Üí baseline vs modelos con features de LLM.
* **F. Evaluaci√≥n comparativa** ‚Üí resultados, impacto y trade-offs.

---

## üë• Integrantes ‚Äì Grupo 4

* Eugenio Negrin
* Ian Link
* Santiago Tedoldi
* Tom√°s Elsesser
* Leopoldo Serpa

---

## üìÖ Hitos

* **10/09/2025** ‚Üí Entrega de **PPT + Dataset**.

---

## ‚öôÔ∏è Tecnolog√≠as y Herramientas

* **Lenguaje:** Python 3.10
* **Librer√≠as:** Scrapy, Pandas, Scikit-learn, AsyncIO, Transformers
* **LLMs:** GPT-4o mini, GPT-5 nano, modelos locales (\~3B)
* **Infraestructura:** GPU Laptop + APIs OpenAI

---

## üìä Resultados esperados

* Dataset curado de noticias con *features* derivadas de LLMs.
* Evaluaci√≥n cuantitativa del valor agregado en modelos macroecon√≥micos.
* Benchmark detallado entre **LLMs en la nube** y **modelos locales**.
* Documento final con conclusiones metodol√≥gicas y t√©cnicas sobre **LLM-based Feature Engineering**.

```

---

¬øQuer√©s que tambi√©n arme un **diagrama simple en Markdown/mermaid** con el pipeline (Scraping ‚Üí Preprocesamiento ‚Üí LLM Features ‚Üí Modelado ‚Üí Evaluaci√≥n)?
```



