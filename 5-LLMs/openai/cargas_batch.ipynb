{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27338ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################################\n",
    "########################################################################################################################################################################\n",
    "############################################################# PIPELINE BATCH PARA EXTRACCIÓN ESTRUCTURADA ##############################################################\n",
    "########################################################################################################################################################################\n",
    "########################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68dbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Librerías.\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "import json, pathlib\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0be85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Constantes.\n",
    "nombre_prueba = input(\"Por favor, asigne un subfijo para el nombre de los archivos output siguiendo el patrón: 'IL1610_1' (inicial nombre, inicial apellido,dia, mes,número de prueba/detalle de prueba):\")\n",
    "project_path = \"C:/Users/i_link/Maestría/Text Mining/nlp_dmuba/\"\n",
    "dataset_file_path = project_path + \"1-Scraping/dataset_consolidado/df.parquet\"\n",
    "batch_requests_path = project_path + \"5-LLMs/openai/pruebas_batch/batch_requests_{}.jsonl\".format(nombre_prueba)\n",
    "batch_results_path =  project_path + \"5-LLMs/openai/pruebas_batch/batch_results_{}.jsonl\".format(nombre_prueba)\n",
    "batch_errors_path =   project_path + \"5-LLMs/openai/pruebas_batch/batch_errors_{}.jsonl\".format(nombre_prueba)\n",
    "df_final_path = project_path + \"5-LLMs/openai/pruebas_batch/df_final_{}.csv\".format(nombre_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65600df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Lecturas.\n",
    "#a. Datos.\n",
    "df = pd.read_parquet(dataset_file_path)\n",
    "#b. Clave API.\n",
    "with open(project_path + \"secrets/opeinai_api_key.txt\", \"r\") as f:\n",
    "    key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c624e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Genero un Cliente de OpenAI.\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d115f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### SAMPLEO PARA PRUEBAS ####################################################\n",
    "sample = 1500\n",
    "df_sample = df.dropna(subset=[\"contenido\"]).sample(sample, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7673a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Prompt. \n",
    "#a. System y User Prompt.\n",
    "SYSTEM_PROMPT = '''\n",
    "Eres un analista económico-financiero especializado en Argentina.\n",
    "Objetivo: extraer datos ESTRUCTURADOS de una noticia para modelar el MERVAL.\n",
    "\n",
    "Salida:\n",
    "Genera SOLO un JSON plano con todas las columnas al mismo nivel. Usa los valores por defecto si no hay información.\n",
    "\n",
    "Campos y definiciones:\n",
    "\n",
    "- tipo_actor_principal: Actor dominante al que refiere la noticia. Posibles valores: \"gobierno_nacional\",\"bcra\",\"provincia\",\"municipio\",\"empresa_local\",\"empresa_extranjera\",\"sindicato\",\"poder_judicial\",\"congreso\",\"organismo_internacional\",\"desconocido\". Default: \"desconocido\"\n",
    "- nombre_actor_principal: Nombre del actor principal si es claro. Default: \"unknown\"\n",
    "- empresas_mencionadas: Lista de empresas mencionadas (nombre legal). Default: []\n",
    "- tickers_mencionados: Lista de tickers (BYMA/ADRs) en MAYÚSCULAS, sin duplicados. Default: []\n",
    "- sectores_mencionados: Lista de sectores/industrias relevantes. Default: []\n",
    "\n",
    "- tipo_evento: Categoría del hecho principal. Posibles valores: \"monetario\",\"fiscal\",\"regulatorio\",\"corporativo\",\"externo\",\"sindical_social\",\"judicial\",\"electoral\",\"otro\",\"desconocido\". Default: \"desconocido\"\n",
    "- shock: Signo cualitativo del impacto sobre mercados o economía. Posibles valores: \"positivo\",\"negativo\",\"mixto\",\"neutro\",\"desconocido\". Default: \"desconocido\"\n",
    "- caracter: Temporalidad del evento. Posibles valores: \"retroactivo\",\"vigente\",\"prospectivo\",\"desconocido\". Default: \"desconocido\"\n",
    "- horizonte_dias: Días hasta que se espera el impacto, si se menciona explícitamente; si no, null. Default: null\n",
    "\n",
    "- merval: Sesgo esperado para el índice Merval (-1: baja fuerte, +1: sube fuerte). Default: 0.0\n",
    "- volatilidad_merval: Indicador cualitativo de volatilidad esperada (-1: baja, +1: alta). Default: 0.0\n",
    "- fx_usdars: Sesgo para el tipo de cambio USD/ARS (-1: aprecia ARS, +1: deprecia ARS). Default: 0.0\n",
    "- spread_usd: Indicador cualitativo de spread dólar oficial vs paralelo (-1: estrecho, +1: amplio). Default: 0.0\n",
    "- tasa_bcra: Sesgo para la tasa de política del BCRA (-1: baja, +1: sube). Default: 0.0\n",
    "- bonos_soberanos: Sesgo sobre precio de bonos soberanos (-1: baja, +1: sube). Default: 0.0\n",
    "- spread_bonos: Indicador cualitativo de spreads de bonos (-1: estrecho, +1: amplio). Default: 0.0\n",
    "- actividad_economica: Sesgo sobre nivel de actividad económica (-1: baja, +1: sube). Default: 0.0\n",
    "- volumen_mercado: Nivel de actividad en trading (-1: bajo, +1: alto). Default: 0.0\n",
    "\n",
    "- valencia_general: Tono general del artículo sobre economía y mercados (-1: negativo, +1: positivo). Default: 0.0\n",
    "- gobernanza: Tono respecto a gobierno o instituciones (-1: negativo, +1: positivo). Default: 0.0\n",
    "- expectativa_macro_corto: Expectativa macro a 1–3 meses (-1: pesimista, +1: optimista). Default: 0.0\n",
    "- expectativa_macro_largo: Expectativa macro a >6 meses (-1: pesimista, +1: optimista). Default: 0.0\n",
    "- expectativa_fin_corto: Expectativa financiera a 1–3 meses (-1: negativo, +1: positivo). Default: 0.0\n",
    "- expectativa_fin_largo: Expectativa financiera a >6 meses (-1: negativo, +1: positivo). Default: 0.0\n",
    "\n",
    "- menciona_inflacion: Se mencionan inflación o precios. Default: false\n",
    "- menciona_pbi: Se menciona PBI o crecimiento económico. Default: false\n",
    "- menciona_reservas: Se mencionan reservas del BCRA. Default: false\n",
    "- menciona_embi: Se menciona riesgo país o EMBI. Default: false\n",
    "- menciona_deuda: Se menciona deuda pública o privada. Default: false\n",
    "- menciona_fmi: Se menciona FMI o acuerdos con el FMI. Default: false\n",
    "- menciona_salarios_paritarias: Se mencionan salarios o paritarias. Default: false\n",
    "- menciona_tipo_cambio: Se menciona tipo de cambio o dólar. Default: false\n",
    "- menciona_confianza_consumidor: Se menciona índice o sentimiento de confianza del consumidor. Default: false\n",
    "\n",
    "- categoria_fuente: Tipo de fuente del contenido. Posibles valores: \"oficial\",\"periodistica\",\"analisis\",\"rumor\",\"desconocido\". Default: \"desconocido\"\n",
    "- score_fuente: Confiabilidad de la fuente según categoría (0..1). Default: 0.5\n",
    "- confianza: Confianza global de extracción (claridad y evidencia) (0..1). Default: 0.0\n",
    "\n",
    "Reglas y robustez:\n",
    "- Usa SOLO el texto de la noticia. NO infieras más allá.\n",
    "- Señales y expectativas macro/financieras solo en [-1..1].\n",
    "- Valores boolean: true/false.\n",
    "- Valores numéricos: float.\n",
    "- Null si no hay información explícita.\n",
    "- Tickers en MAYÚSCULAS; listas sin duplicados.\n",
    "- Listas siempre en formato JSON array, aunque estén vacías.\n",
    "- Si el artículo no es económico/financiero (ej.: cultura, deportes, política sin relación económica), llenar señales y expectativas con 0.0, booleanos con false, tipo_evento=\"desconocido\", confianza ≤ 0.3.\n",
    "- Contenido puede ser truncado a X caracteres si es muy extenso.\n",
    "\n",
    "Instrucciones finales:\n",
    "- Devuelve SOLO JSON plano, sin anidamiento ni explicaciones.\n",
    "- Respeta todos los tipos (boolean, string, float, null).\n",
    "- No agregues texto adicional ni explicaciones.\n",
    "'''\n",
    "\n",
    "\n",
    "USER_TEMPLATE = '''\n",
    "Diario: {diario}\n",
    "Fecha: {fecha}  # formato YYYY-MM-DD.\n",
    "Seccion: {seccion}\n",
    "Titulo: {titulo}\n",
    "Contenido: {contenido}  # truncado a 8000 caracteres si es muy largo.\n",
    "\n",
    "Instrucciones:\n",
    "- Genera SOLO un JSON plano con todos los campos al mismo nivel, siguiendo el esquema definido en el SYSTEM_PROMPT.\n",
    "- No agregues texto adicional ni explicaciones.\n",
    "- Respeta tipos de datos, valores por defecto y rangos.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivo JSONL creado en batch_request\n"
     ]
    }
   ],
   "source": [
    "#6. Creo archivo JSONL para carga batch,\n",
    "with open(batch_requests_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, row in df_sample.iterrows():\n",
    "        contenido = (row.get(\"contenido\") or \"\")[:8000]\n",
    "        prompt = USER_TEMPLATE.format(\n",
    "            diario=row.get(\"diario\", \"unknown\"),\n",
    "            fecha=str(row.get(\"fecha\", \"unknown\")),\n",
    "            seccion=row.get(\"seccion\", \"unknown\"),\n",
    "            titulo=row.get(\"titulo\", \"unknown\"),\n",
    "            contenido=contenido\n",
    "        )\n",
    "\n",
    "        request_dict = {\n",
    "            \"custom_id\": f\"row_{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/responses\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"input\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "\n",
    "        }\n",
    "        f.write(json.dumps(request_dict, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"✅ Archivo JSONL creado en batch_request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3a4ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Archivo subido con ID: file-Ws2L4D3G5FNdfSoZkbpVat\n",
      "🚀 Batch job creado: batch_68f1677d914c8190a66da06f042705a9\n",
      "Status inicial: validating\n"
     ]
    }
   ],
   "source": [
    "#7. Subo el archivo y cargo el batch.\n",
    "#a. Subo el archivo JSONL.\n",
    "file_upload = client.files.create(\n",
    "    file=open(batch_requests_path, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(\"📁 Archivo subido con ID:\", file_upload.id)\n",
    "\n",
    "#b. Creo el batch job usando ese file_id.\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=file_upload.id,\n",
    "    endpoint=\"/v1/responses\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "print(\"🚀 Batch job creado:\", batch_job.id)\n",
    "print(\"Status inicial:\", batch_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee0c611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Estado: completed\n",
      "⚙️  Output file: file-YFZyJoUXwm5htHFjai4wTE\n",
      "📦 ID: batch_68f1677d914c8190a66da06f042705a9\n",
      "🕒 Creado: 1760651133\n",
      "{'cancelled_at': None,\n",
      " 'cancelling_at': None,\n",
      " 'completed_at': 1760651811,\n",
      " 'completion_window': '24h',\n",
      " 'created_at': 1760651133,\n",
      " 'endpoint': '/v1/responses',\n",
      " 'error_file_id': None,\n",
      " 'errors': None,\n",
      " 'expired_at': None,\n",
      " 'expires_at': 1760737533,\n",
      " 'failed_at': None,\n",
      " 'finalizing_at': 1760651607,\n",
      " 'id': 'batch_68f1677d914c8190a66da06f042705a9',\n",
      " 'in_progress_at': 1760651135,\n",
      " 'input_file_id': 'file-Ws2L4D3G5FNdfSoZkbpVat',\n",
      " 'metadata': None,\n",
      " 'model': 'gpt-5-mini-2025-08-07',\n",
      " 'object': 'batch',\n",
      " 'output_file_id': 'file-YFZyJoUXwm5htHFjai4wTE',\n",
      " 'request_counts': {'completed': 1500, 'failed': 0, 'total': 1500},\n",
      " 'status': 'completed',\n",
      " 'usage': {'input_tokens': 3639440,\n",
      "           'input_tokens_details': {'cached_tokens': 1694720},\n",
      "           'output_tokens': 2666575,\n",
      "           'output_tokens_details': {'reasoning_tokens': 1988032},\n",
      "           'total_tokens': 6306015}}\n"
     ]
    }
   ],
   "source": [
    "#8. Conozco el estado de lo que envié.\n",
    "#a. Consulto.\n",
    "job = client.batches.retrieve(batch_job.id)\n",
    "#b. Printeo.\n",
    "print(\"📋 Estado:\", job.status)\n",
    "print(\"⚙️  Output file:\", job.output_file_id)\n",
    "print(\"📦 ID:\", job.id)\n",
    "print(\"🕒 Creado:\", job.created_at)\n",
    "pprint(job.model_dump()) # Muestro todos los detalles en bruto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9ca60887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ No hay archivo de errores para este job (error_file_id es None).\n"
     ]
    }
   ],
   "source": [
    "#9. Conozco errores.\n",
    "if job.error_file_id:\n",
    "    #a. Consulto.\n",
    "    error_file_id = job.error_file_id\n",
    "\n",
    "    #b. Descargo el archivo con errores.\n",
    "    error_content = client.files.content(error_file_id)\n",
    "\n",
    "    #c. Almaceno.\n",
    "    with open(batch_errors_path.format(nombre_prueba), \"wb\") as f:\n",
    "        f.write(error_content.read())\n",
    "\n",
    "    # d. Printeo.\n",
    "    print(\"✅ Archivo de errores descargado en batch_errors\")\n",
    "else:\n",
    "    print(\"ℹ️ No hay archivo de errores para este job (error_file_id es None).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "224ea524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Resultados descargados en batch_results.\n"
     ]
    }
   ],
   "source": [
    "#10. Descargo resultados, si está completado.\n",
    "if job.status == \"completed\":\n",
    "    output_file_id = job.output_file_id\n",
    "    result = client.files.content(output_file_id)\n",
    "    \n",
    "    # El contenido es un JSONL (una respuesta por línea)\n",
    "    with open(batch_results_path, \"wb\") as f:\n",
    "        f.write(result.read())\n",
    "\n",
    "    print(\"✅ Resultados descargados en batch_results.\")\n",
    "else:\n",
    "    print(\"ℹ️ Resultados aún no completos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f2ff85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#11. Armo el dataframe.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mjob\u001b[49m.status == \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#a. \"Cargo el JSONL completo de respuestas de la API.\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(batch_results_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m         batch_responses = [json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "\u001b[31mNameError\u001b[39m: name 'job' is not defined"
     ]
    }
   ],
   "source": [
    "#11. Armo el dataframe.\n",
    "if job.status == \"completed\":\n",
    "    #a. \"Cargo el JSONL completo de respuestas de la API.\n",
    "    with open(batch_results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        batch_responses = [json.loads(line) for line in f]\n",
    "\n",
    "    #b. Extraigo toda la info de cada respuesta.\n",
    "    all_records = []\n",
    "    for resp in batch_responses:\n",
    "        try:\n",
    "            # Extraigo el JSON generado por el modelo.\n",
    "            text_json_str = resp[\"response\"][\"body\"][\"output\"][1][\"content\"][0][\"text\"]\n",
    "            data = json.loads(text_json_str)\n",
    "            \n",
    "            # Agrego el custom_id para poder unirlo con el DataFrame original.\n",
    "            data[\"custom_id\"] = resp.get(\"custom_id\", None)\n",
    "            all_records.append(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error en registro {resp.get('custom_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "    #c. Creo DataFrame plano con todas las columnas extraídas.\n",
    "    df_features = pd.json_normalize(all_records)\n",
    "\n",
    "    #d. Agrego columna custom_id al df original para poder hacer merge.\n",
    "    df_sample['custom_id'] = [f'row_{i}' for i in range(len(df_sample))]\n",
    "\n",
    "    #e. Uno el df original con las features extraídas.\n",
    "    df_final = df_sample.merge(df_features, on='custom_id', how='left')\n",
    "\n",
    "    #f. Elimino custom_id si ya no sirve.\n",
    "    df_final.drop(columns=[\"custom_id\"], inplace=True)\n",
    "\n",
    "    #g. Exporto el resultado.\n",
    "    df_final.to_csv(df_final_path,index=False)\n",
    "else:\n",
    "    print(\"ℹ️ Resultados aún no completos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a757fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏱ Duración del proceso: 0:11:18\n",
      "Duración en segundos: 678.0\n",
      "Duración en minutos: 11.3\n"
     ]
    }
   ],
   "source": [
    "#12. Visualizo cuanto tardó el proceso.\n",
    "if job.status == \"completed\":\n",
    "    #a. Convertimos timestamps a datetime.\n",
    "    created = datetime.fromtimestamp(job.created_at)\n",
    "    completed = datetime.fromtimestamp(job.completed_at)\n",
    "\n",
    "    #b. Calculamos duración.\n",
    "    duration = completed - created\n",
    "    print(\"⏱ Duración del proceso:\", duration)\n",
    "    print(\"Duración en segundos:\", (completed - created).total_seconds())\n",
    "    print(\"Duración en minutos:\", (completed - created).total_seconds()/60)\n",
    "else:\n",
    "    print(\"ℹ️ Resultados aún no completos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
