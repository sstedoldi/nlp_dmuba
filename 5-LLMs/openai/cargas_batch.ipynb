{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "27338ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################################################################\n",
    "########################################################################################################################################################################\n",
    "############################################################# PIPELINE BATCH PARA EXTRACCI√ìN ESTRUCTURADA ##############################################################\n",
    "########################################################################################################################################################################\n",
    "########################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68dbc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Librer√≠as.\n",
    "from __future__ import annotations\n",
    "from typing import List, Optional, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "import pandas as pd\n",
    "import json, pathlib\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae0be85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Constantes.\n",
    "nombre_prueba = input(\"Por favor, asigne un subfijo para el nombre de los archivos output siguiendo el patr√≥n: 'IL1610_1' (inicial nombre, inicial apellido,dia, mes,n√∫mero de prueba/detalle de prueba):\")\n",
    "project_path = \"C:/Users/i_link/Maestr√≠a/Text Mining/nlp_dmuba/\"\n",
    "dataset_file_path = project_path + \"1-Scraping/dataset_consolidado/df.parquet\"\n",
    "batch_requests_path = project_path + \"5-LLMs/openai/pruebas_batch/batch_requests_{}.jsonl\".format(nombre_prueba)\n",
    "batch_results_path =  project_path + \"5-LLMs/openai/pruebas_batch/batch_results_{}.jsonl\".format(nombre_prueba)\n",
    "batch_errors_path =   project_path + \"5-LLMs/openai/pruebas_batch/batch_errors_{}.jsonl\".format(nombre_prueba)\n",
    "df_final_path = project_path + \"5-LLMs/openai/pruebas_batch/df_final_{}.csv\".format(nombre_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65600df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Lecturas.\n",
    "#a. Datos.\n",
    "df = pd.read_parquet(dataset_file_path)\n",
    "#b. Clave API.\n",
    "with open(project_path + \"secrets/opeinai_api_key.txt\", \"r\") as f:\n",
    "    key = f.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c624e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Genero un Cliente de OpenAI.\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d115f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### SAMPLEO PARA PRUEBAS ####################################################\n",
    "sample = 1500\n",
    "df_sample = df.dropna(subset=[\"contenido\"]).sample(sample, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7673a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Prompt. \n",
    "#a. System y User Prompt.\n",
    "SYSTEM_PROMPT = '''\n",
    "Eres un analista econ√≥mico-financiero especializado en Argentina.\n",
    "Objetivo: extraer datos ESTRUCTURADOS de una noticia para modelar el MERVAL.\n",
    "\n",
    "Salida:\n",
    "Genera SOLO un JSON plano con todas las columnas al mismo nivel. Usa los valores por defecto si no hay informaci√≥n.\n",
    "\n",
    "Campos y definiciones:\n",
    "\n",
    "- tipo_actor_principal: Actor dominante al que refiere la noticia. Posibles valores: \"gobierno_nacional\",\"bcra\",\"provincia\",\"municipio\",\"empresa_local\",\"empresa_extranjera\",\"sindicato\",\"poder_judicial\",\"congreso\",\"organismo_internacional\",\"desconocido\". Default: \"desconocido\"\n",
    "- nombre_actor_principal: Nombre del actor principal si es claro. Default: \"unknown\"\n",
    "- empresas_mencionadas: Lista de empresas mencionadas (nombre legal). Default: []\n",
    "- tickers_mencionados: Lista de tickers (BYMA/ADRs) en MAY√öSCULAS, sin duplicados. Default: []\n",
    "- sectores_mencionados: Lista de sectores/industrias relevantes. Default: []\n",
    "\n",
    "- tipo_evento: Categor√≠a del hecho principal. Posibles valores: \"monetario\",\"fiscal\",\"regulatorio\",\"corporativo\",\"externo\",\"sindical_social\",\"judicial\",\"electoral\",\"otro\",\"desconocido\". Default: \"desconocido\"\n",
    "- shock: Signo cualitativo del impacto sobre mercados o econom√≠a. Posibles valores: \"positivo\",\"negativo\",\"mixto\",\"neutro\",\"desconocido\". Default: \"desconocido\"\n",
    "- caracter: Temporalidad del evento. Posibles valores: \"retroactivo\",\"vigente\",\"prospectivo\",\"desconocido\". Default: \"desconocido\"\n",
    "- horizonte_dias: D√≠as hasta que se espera el impacto, si se menciona expl√≠citamente; si no, null. Default: null\n",
    "\n",
    "- merval: Sesgo esperado para el √≠ndice Merval (-1: baja fuerte, +1: sube fuerte). Default: 0.0\n",
    "- volatilidad_merval: Indicador cualitativo de volatilidad esperada (-1: baja, +1: alta). Default: 0.0\n",
    "- fx_usdars: Sesgo para el tipo de cambio USD/ARS (-1: aprecia ARS, +1: deprecia ARS). Default: 0.0\n",
    "- spread_usd: Indicador cualitativo de spread d√≥lar oficial vs paralelo (-1: estrecho, +1: amplio). Default: 0.0\n",
    "- tasa_bcra: Sesgo para la tasa de pol√≠tica del BCRA (-1: baja, +1: sube). Default: 0.0\n",
    "- bonos_soberanos: Sesgo sobre precio de bonos soberanos (-1: baja, +1: sube). Default: 0.0\n",
    "- spread_bonos: Indicador cualitativo de spreads de bonos (-1: estrecho, +1: amplio). Default: 0.0\n",
    "- actividad_economica: Sesgo sobre nivel de actividad econ√≥mica (-1: baja, +1: sube). Default: 0.0\n",
    "- volumen_mercado: Nivel de actividad en trading (-1: bajo, +1: alto). Default: 0.0\n",
    "\n",
    "- valencia_general: Tono general del art√≠culo sobre econom√≠a y mercados (-1: negativo, +1: positivo). Default: 0.0\n",
    "- gobernanza: Tono respecto a gobierno o instituciones (-1: negativo, +1: positivo). Default: 0.0\n",
    "- expectativa_macro_corto: Expectativa macro a 1‚Äì3 meses (-1: pesimista, +1: optimista). Default: 0.0\n",
    "- expectativa_macro_largo: Expectativa macro a >6 meses (-1: pesimista, +1: optimista). Default: 0.0\n",
    "- expectativa_fin_corto: Expectativa financiera a 1‚Äì3 meses (-1: negativo, +1: positivo). Default: 0.0\n",
    "- expectativa_fin_largo: Expectativa financiera a >6 meses (-1: negativo, +1: positivo). Default: 0.0\n",
    "\n",
    "- menciona_inflacion: Se mencionan inflaci√≥n o precios. Default: false\n",
    "- menciona_pbi: Se menciona PBI o crecimiento econ√≥mico. Default: false\n",
    "- menciona_reservas: Se mencionan reservas del BCRA. Default: false\n",
    "- menciona_embi: Se menciona riesgo pa√≠s o EMBI. Default: false\n",
    "- menciona_deuda: Se menciona deuda p√∫blica o privada. Default: false\n",
    "- menciona_fmi: Se menciona FMI o acuerdos con el FMI. Default: false\n",
    "- menciona_salarios_paritarias: Se mencionan salarios o paritarias. Default: false\n",
    "- menciona_tipo_cambio: Se menciona tipo de cambio o d√≥lar. Default: false\n",
    "- menciona_confianza_consumidor: Se menciona √≠ndice o sentimiento de confianza del consumidor. Default: false\n",
    "\n",
    "- categoria_fuente: Tipo de fuente del contenido. Posibles valores: \"oficial\",\"periodistica\",\"analisis\",\"rumor\",\"desconocido\". Default: \"desconocido\"\n",
    "- score_fuente: Confiabilidad de la fuente seg√∫n categor√≠a (0..1). Default: 0.5\n",
    "- confianza: Confianza global de extracci√≥n (claridad y evidencia) (0..1). Default: 0.0\n",
    "\n",
    "Reglas y robustez:\n",
    "- Usa SOLO el texto de la noticia. NO infieras m√°s all√°.\n",
    "- Se√±ales y expectativas macro/financieras solo en [-1..1].\n",
    "- Valores boolean: true/false.\n",
    "- Valores num√©ricos: float.\n",
    "- Null si no hay informaci√≥n expl√≠cita.\n",
    "- Tickers en MAY√öSCULAS; listas sin duplicados.\n",
    "- Listas siempre en formato JSON array, aunque est√©n vac√≠as.\n",
    "- Si el art√≠culo no es econ√≥mico/financiero (ej.: cultura, deportes, pol√≠tica sin relaci√≥n econ√≥mica), llenar se√±ales y expectativas con 0.0, booleanos con false, tipo_evento=\"desconocido\", confianza ‚â§ 0.3.\n",
    "- Contenido puede ser truncado a X caracteres si es muy extenso.\n",
    "\n",
    "Instrucciones finales:\n",
    "- Devuelve SOLO JSON plano, sin anidamiento ni explicaciones.\n",
    "- Respeta todos los tipos (boolean, string, float, null).\n",
    "- No agregues texto adicional ni explicaciones.\n",
    "'''\n",
    "\n",
    "\n",
    "USER_TEMPLATE = '''\n",
    "Diario: {diario}\n",
    "Fecha: {fecha}  # formato YYYY-MM-DD.\n",
    "Seccion: {seccion}\n",
    "Titulo: {titulo}\n",
    "Contenido: {contenido}  # truncado a 8000 caracteres si es muy largo.\n",
    "\n",
    "Instrucciones:\n",
    "- Genera SOLO un JSON plano con todos los campos al mismo nivel, siguiendo el esquema definido en el SYSTEM_PROMPT.\n",
    "- No agregues texto adicional ni explicaciones.\n",
    "- Respeta tipos de datos, valores por defecto y rangos.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo JSONL creado en batch_request\n"
     ]
    }
   ],
   "source": [
    "#6. Creo archivo JSONL para carga batch,\n",
    "with open(batch_requests_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, row in df_sample.iterrows():\n",
    "        contenido = (row.get(\"contenido\") or \"\")[:8000]\n",
    "        prompt = USER_TEMPLATE.format(\n",
    "            diario=row.get(\"diario\", \"unknown\"),\n",
    "            fecha=str(row.get(\"fecha\", \"unknown\")),\n",
    "            seccion=row.get(\"seccion\", \"unknown\"),\n",
    "            titulo=row.get(\"titulo\", \"unknown\"),\n",
    "            contenido=contenido\n",
    "        )\n",
    "\n",
    "        request_dict = {\n",
    "            \"custom_id\": f\"row_{i}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/responses\",\n",
    "            \"body\": {\n",
    "                \"model\": \"gpt-5-mini\",\n",
    "                \"input\": [\n",
    "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "\n",
    "        }\n",
    "        f.write(json.dumps(request_dict, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Archivo JSONL creado en batch_request.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3a4ae09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Archivo subido con ID: file-Ws2L4D3G5FNdfSoZkbpVat\n",
      "üöÄ Batch job creado: batch_68f1677d914c8190a66da06f042705a9\n",
      "Status inicial: validating\n"
     ]
    }
   ],
   "source": [
    "#7. Subo el archivo y cargo el batch.\n",
    "#a. Subo el archivo JSONL.\n",
    "file_upload = client.files.create(\n",
    "    file=open(batch_requests_path, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "print(\"üìÅ Archivo subido con ID:\", file_upload.id)\n",
    "\n",
    "#b. Creo el batch job usando ese file_id.\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=file_upload.id,\n",
    "    endpoint=\"/v1/responses\",\n",
    "    completion_window=\"24h\"\n",
    ")\n",
    "\n",
    "print(\"üöÄ Batch job creado:\", batch_job.id)\n",
    "print(\"Status inicial:\", batch_job.status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee0c611e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Estado: completed\n",
      "‚öôÔ∏è  Output file: file-YFZyJoUXwm5htHFjai4wTE\n",
      "üì¶ ID: batch_68f1677d914c8190a66da06f042705a9\n",
      "üïí Creado: 1760651133\n",
      "{'cancelled_at': None,\n",
      " 'cancelling_at': None,\n",
      " 'completed_at': 1760651811,\n",
      " 'completion_window': '24h',\n",
      " 'created_at': 1760651133,\n",
      " 'endpoint': '/v1/responses',\n",
      " 'error_file_id': None,\n",
      " 'errors': None,\n",
      " 'expired_at': None,\n",
      " 'expires_at': 1760737533,\n",
      " 'failed_at': None,\n",
      " 'finalizing_at': 1760651607,\n",
      " 'id': 'batch_68f1677d914c8190a66da06f042705a9',\n",
      " 'in_progress_at': 1760651135,\n",
      " 'input_file_id': 'file-Ws2L4D3G5FNdfSoZkbpVat',\n",
      " 'metadata': None,\n",
      " 'model': 'gpt-5-mini-2025-08-07',\n",
      " 'object': 'batch',\n",
      " 'output_file_id': 'file-YFZyJoUXwm5htHFjai4wTE',\n",
      " 'request_counts': {'completed': 1500, 'failed': 0, 'total': 1500},\n",
      " 'status': 'completed',\n",
      " 'usage': {'input_tokens': 3639440,\n",
      "           'input_tokens_details': {'cached_tokens': 1694720},\n",
      "           'output_tokens': 2666575,\n",
      "           'output_tokens_details': {'reasoning_tokens': 1988032},\n",
      "           'total_tokens': 6306015}}\n"
     ]
    }
   ],
   "source": [
    "#8. Conozco el estado de lo que envi√©.\n",
    "#a. Consulto.\n",
    "job = client.batches.retrieve(batch_job.id)\n",
    "#b. Printeo.\n",
    "print(\"üìã Estado:\", job.status)\n",
    "print(\"‚öôÔ∏è  Output file:\", job.output_file_id)\n",
    "print(\"üì¶ ID:\", job.id)\n",
    "print(\"üïí Creado:\", job.created_at)\n",
    "pprint(job.model_dump()) # Muestro todos los detalles en bruto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "9ca60887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No hay archivo de errores para este job (error_file_id es None).\n"
     ]
    }
   ],
   "source": [
    "#9. Conozco errores.\n",
    "if job.error_file_id:\n",
    "    #a. Consulto.\n",
    "    error_file_id = job.error_file_id\n",
    "\n",
    "    #b. Descargo el archivo con errores.\n",
    "    error_content = client.files.content(error_file_id)\n",
    "\n",
    "    #c. Almaceno.\n",
    "    with open(batch_errors_path.format(nombre_prueba), \"wb\") as f:\n",
    "        f.write(error_content.read())\n",
    "\n",
    "    # d. Printeo.\n",
    "    print(\"‚úÖ Archivo de errores descargado en batch_errors\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è No hay archivo de errores para este job (error_file_id es None).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "224ea524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Resultados descargados en batch_results.\n"
     ]
    }
   ],
   "source": [
    "#10. Descargo resultados, si est√° completado.\n",
    "if job.status == \"completed\":\n",
    "    output_file_id = job.output_file_id\n",
    "    result = client.files.content(output_file_id)\n",
    "    \n",
    "    # El contenido es un JSONL (una respuesta por l√≠nea)\n",
    "    with open(batch_results_path, \"wb\") as f:\n",
    "        f.write(result.read())\n",
    "\n",
    "    print(\"‚úÖ Resultados descargados en batch_results.\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Resultados a√∫n no completos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f2ff85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'job' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#11. Armo el dataframe.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mjob\u001b[49m.status == \u001b[33m\"\u001b[39m\u001b[33mcompleted\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m#a. \"Cargo el JSONL completo de respuestas de la API.\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(batch_results_path, \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m         batch_responses = [json.loads(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "\u001b[31mNameError\u001b[39m: name 'job' is not defined"
     ]
    }
   ],
   "source": [
    "#11. Armo el dataframe.\n",
    "if job.status == \"completed\":\n",
    "    #a. \"Cargo el JSONL completo de respuestas de la API.\n",
    "    with open(batch_results_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        batch_responses = [json.loads(line) for line in f]\n",
    "\n",
    "    #b. Extraigo toda la info de cada respuesta.\n",
    "    all_records = []\n",
    "    for resp in batch_responses:\n",
    "        try:\n",
    "            # Extraigo el JSON generado por el modelo.\n",
    "            text_json_str = resp[\"response\"][\"body\"][\"output\"][1][\"content\"][0][\"text\"]\n",
    "            data = json.loads(text_json_str)\n",
    "            \n",
    "            # Agrego el custom_id para poder unirlo con el DataFrame original.\n",
    "            data[\"custom_id\"] = resp.get(\"custom_id\", None)\n",
    "            all_records.append(data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error en registro {resp.get('custom_id', 'unknown')}: {e}\")\n",
    "            continue\n",
    "\n",
    "    #c. Creo DataFrame plano con todas las columnas extra√≠das.\n",
    "    df_features = pd.json_normalize(all_records)\n",
    "\n",
    "    #d. Agrego columna custom_id al df original para poder hacer merge.\n",
    "    df_sample['custom_id'] = [f'row_{i}' for i in range(len(df_sample))]\n",
    "\n",
    "    #e. Uno el df original con las features extra√≠das.\n",
    "    df_final = df_sample.merge(df_features, on='custom_id', how='left')\n",
    "\n",
    "    #f. Elimino custom_id si ya no sirve.\n",
    "    df_final.drop(columns=[\"custom_id\"], inplace=True)\n",
    "\n",
    "    #g. Exporto el resultado.\n",
    "    df_final.to_csv(df_final_path,index=False)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Resultados a√∫n no completos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3a757fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è± Duraci√≥n del proceso: 0:11:18\n",
      "Duraci√≥n en segundos: 678.0\n",
      "Duraci√≥n en minutos: 11.3\n"
     ]
    }
   ],
   "source": [
    "#12. Visualizo cuanto tard√≥ el proceso.\n",
    "if job.status == \"completed\":\n",
    "    #a. Convertimos timestamps a datetime.\n",
    "    created = datetime.fromtimestamp(job.created_at)\n",
    "    completed = datetime.fromtimestamp(job.completed_at)\n",
    "\n",
    "    #b. Calculamos duraci√≥n.\n",
    "    duration = completed - created\n",
    "    print(\"‚è± Duraci√≥n del proceso:\", duration)\n",
    "    print(\"Duraci√≥n en segundos:\", (completed - created).total_seconds())\n",
    "    print(\"Duraci√≥n en minutos:\", (completed - created).total_seconds()/60)\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è Resultados a√∫n no completos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
